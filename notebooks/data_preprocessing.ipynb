{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing for Phishing Email Detector\n",
    "\n",
    "This notebook is designed to preprocess the datasets used for training and testing the phishing email detection models. It includes steps for loading, cleaning, and preparing the Enron and phishing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Define function to clean email text\n",
    "def clean_email(text):\n",
    "    text = re.sub(r'\\n', ' ', text)  # Remove newlines\n",
    "    text = re.sub(r'\\r', ' ', text)  # Remove carriage returns\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
    "    text = re.sub(r'[^a-zA-Z0-9 ]', '', text)  # Remove special characters\n",
    "    return text.lower()  # Convert to lowercase\n",
    "\n",
    "# Load Enron dataset\n",
    "enron_path = '../data/enron/'\n",
    "enron_files = [f for f in os.listdir(enron_path) if f.endswith('.csv')]\n",
    "enron_data = pd.concat([pd.read_csv(os.path.join(enron_path, f)) for f in enron_files], ignore_index=True)\n",
    "\n",
    "# Load phishing dataset\n",
    "phishing_path = '../data/phishing/'\n",
    "phishing_files = [f for f in os.listdir(phishing_path) if f.endswith('.csv')]\n",
    "phishing_data = pd.concat([pd.read_csv(os.path.join(phishing_path, f)) for f in phishing_files], ignore_index=True)\n",
    "\n",
    "# Clean the email text in both datasets\n",
    "enron_data['cleaned_text'] = enron_data['email_text'].apply(clean_email)\n",
    "phishing_data['cleaned_text'] = phishing_data['email_text'].apply(clean_email)\n",
    "\n",
    "# Combine datasets and create labels\n",
    "enron_data['label'] = 0  # Legitimate emails\n",
    "phishing_data['label'] = 1  # Phishing emails\n",
    "combined_data = pd.concat([enron_data[['cleaned_text', 'label']], phishing_data[['cleaned_text', 'label']]], ignore_index=True)\n",
    "\n",
    "# Shuffle the combined dataset\n",
    "combined_data = shuffle(combined_data, random_state=42)\n",
    "\n",
    "# Split into training and testing sets\n",
    "train_data, test_data = train_test_split(combined_data, test_size=0.2, random_state=42, stratify=combined_data['label'])\n",
    "\n",
    "# Save the preprocessed data\n",
    "train_data.to_csv('../data/preprocessed_train_data.csv', index=False)\n",
    "test_data.to_csv('../data/preprocessed_test_data.csv', index=False)\n",
    "\n",
    "print('Data preprocessing completed and saved to CSV files.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}